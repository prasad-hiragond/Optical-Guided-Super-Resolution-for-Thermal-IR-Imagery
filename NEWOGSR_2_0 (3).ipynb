{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.10"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "E2lvN7ueaJvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d776166-45f5-426c-f1e7-0f06729dc8c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tof640u22zyW",
        "outputId": "ae7f8b2d-b909-40a4-d957-98928f8bbfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "✓ Using device: cuda\n",
            "✓ Checkpoints will be saved to: /content/drive/MyDrive/SIH_Model_Checkpoints_V2/\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import models  # NEW: For perceptual loss\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm  # NEW: For progress bars\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "class Config:\n",
        "    # Training Settings\n",
        "    NUM_EPOCHS = 100\n",
        "    BATCH_SIZE = 4 # Reduced batch size to help with CUDA out of memory errors\n",
        "    LR = 2e-4\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Loss Weights\n",
        "    LAMBDA_PIXEL = 200 # Increased from 150\n",
        "    LAMBDA_PERCEPTUAL = 10\n",
        "    LAMBDA_EDGE = 20\n",
        "    LAMBDA_PHYSICS = 50\n",
        "    LAMBDA_ADVERSARIAL = 1\n",
        "\n",
        "    # Physics Constants\n",
        "    SIGMA = 5.67e-8\n",
        "    L_DOWNWELLING = 50.\n",
        "\n",
        "    # Paths - UPDATE THESE TO YOUR PATHS\n",
        "    LR_THERMAL_PATH = \"/content/drive/MyDrive/BD\"\n",
        "    HR_OPTICAL_PATH = \"/content/drive/MyDrive/HR RGB\"\n",
        "    HR_THERMAL_PATH = \"/content/drive/MyDrive/GT thermal\"\n",
        "\n",
        "    # Corrected Test Paths (using the provided path as a potential test path)\n",
        "    TEST_LR_THERMAL_PATH = \"/content/drive/MyDrive/BD\" # Using the provided path\n",
        "    # TEST_LR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/BD\" # Original test path\n",
        "    TEST_HR_OPTICAL_PATH = \"/content/drive/MyDrive/HR RGB\" # Using the provided path\n",
        "    # TEST_HR_OPTICAL_PATH = \"/content/drive/MyDrive/TestData/HR RGB\" # Original test path\n",
        "    TEST_HR_THERMAL_PATH = \"/content/drive/MyDrive/GT thermal\" # Using the provided path\n",
        "    # TEST_HR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/GT thermal\" # Original test path\n",
        "\n",
        "\n",
        "    CHECKPOINT_DIR = \"/content/drive/MyDrive/SIH_Model_Checkpoints_V2/\" # Keep the same checkpoint directory for now\n",
        "\n",
        "    # Training Settings\n",
        "    VAL_SPLIT = 0.15\n",
        "    EARLY_STOPPING_PATIENCE = 25\n",
        "    SAVE_EVERY_N_EPOCHS = 5\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "print(f\"✓ Using device: {config.DEVICE}\")\n",
        "print(f\"✓ Checkpoints will be saved to: {config.CHECKPOINT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0daca60",
        "outputId": "d53489ed-ae05-4185-9af9-82208a7a78ba"
      },
      "source": [
        "    # Paths - UPDATE THESE TO YOUR PATHS\n",
        "LR_THERMAL_PATH = \"/content/drive/MyDrive/BD\"\n",
        "    HR_OPTICAL_PATH = \"/content/drive/MyDrive/HR RGB\"\n",
        "    HR_THERMAL_PATH = \"/content/drive/MyDrive/GT thermal\"\n",
        "\n",
        "    TEST_LR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/BD\"\n",
        "    TEST_HR_OPTICAL_PATH = \"/content/drive/MyDrive/TestData/HR RGB\"\n",
        "    TEST_HR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/GT thermal\"\n",
        "\n",
        "    CHECKPOINT_DIR = \"/content/drive/MyDrive/SIH_Model_Checkpoints_V2/\"\n",
        "\n",
        "    # Training Settings\n",
        "    VAL_SPLIT = 0.15\n",
        "    EARLY_STOPPING_PATIENCE = 15\n",
        "    SAVE_EVERY_N_EPOCHS = 5\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "print(f\"✓ Using device: {config.DEVICE}\")\n",
        "print(f\"✓ Checkpoints will be saved to: {config.CHECKPOINT_DIR}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Using device: cuda\n",
            "✓ Checkpoints will be saved to: /content/drive/MyDrive/SIH_Model_Checkpoints_V2/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths - UPDATE THESE TO YOUR PATHS\n",
        "#LR_THERMAL_PATH = \"/content/drive/MyDrive/BD\"\n",
        "#HR_OPTICAL_PATH = \"/content/drive/MyDrive/HR RGB\"\n",
        "#HR_THERMAL_PATH = \"/content/drive/MyDrive/GT thermal\"\n",
        "\n",
        "#TEST_LR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/BD\"\n",
        "#TEST_HR_OPTICAL_PATH = \"/content/drive/MyDrive/TestData/HR RGB\"\n",
        "#TEST_HR_THERMAL_PATH = \"/content/drive/MyDrive/TestData/GT thermal\"\n",
        "\n",
        "#CHECKPOINT_DIR = \"/content/drive/MyDrive/SIH_Model_Checkpoints_V2/\"  # New folder\n",
        "\n",
        "# Training Settings\n",
        "#VAL_SPLIT = 0.15\n",
        "#EARLY_STOPPING_PATIENCE = 15\n",
        "#SAVE_EVERY_N_EPOCHS = 5\n",
        "\n",
        "#config = Config()\n",
        "#os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "#print(f\"✓ Using device: {config.DEVICE}\")\n",
        "#print(f\"✓ Checkpoints will be saved to: {config.CHECKPOINT_DIR}\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 4: IMPROVED DATASET WITH AUGMENTATION\n",
        "# ==========================================\n",
        "# REPLACE your IndexedThermalDataset with this:\n",
        "\n",
        "import random\n",
        "\n",
        "class ImprovedThermalDataset(Dataset):\n",
        "    def __init__(self, lr_path, hr_optical_path, hr_thermal_path, augment=True):\n",
        "        self.lr_thermal_path = lr_path\n",
        "        self.hr_optical_path = hr_optical_path\n",
        "        self.hr_thermal_path = hr_thermal_path\n",
        "        self.augment = augment\n",
        "\n",
        "        self.lr_thermal_files = sorted(os.listdir(self.lr_thermal_path))\n",
        "        self.hr_optical_files = sorted(os.listdir(self.hr_optical_path))\n",
        "        self.hr_thermal_files = sorted(os.listdir(self.hr_thermal_path))\n",
        "\n",
        "        # Basic transforms\n",
        "        self.transform_gray = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        self.transform_rgb = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # Augmentation transforms\n",
        "        self.transform_gray_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        self.transform_rgb_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_thermal_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        lr_thermal_img = Image.open(os.path.join(self.lr_thermal_path, self.lr_thermal_files[index])).convert(\"L\")\n",
        "        hr_optical_img = Image.open(os.path.join(self.hr_optical_path, self.hr_optical_files[index])).convert(\"RGB\")\n",
        "        hr_thermal_img = Image.open(os.path.join(self.hr_thermal_path, self.hr_thermal_files[index])).convert(\"L\")\n",
        "\n",
        "        if self.augment:\n",
        "            # Use same random seed for consistent augmentation\n",
        "            seed = random.randint(0, 2**32)\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            lr_thermal = self.transform_gray_aug(lr_thermal_img)\n",
        "\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_optical = self.transform_rgb_aug(hr_optical_img)\n",
        "\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_thermal = self.transform_gray_aug(hr_thermal_img)\n",
        "        else:\n",
        "            lr_thermal = self.transform_gray(lr_thermal_img)\n",
        "            hr_optical = self.transform_rgb(hr_optical_img)\n",
        "            hr_thermal = self.transform_gray(hr_thermal_img)\n",
        "\n",
        "        return lr_thermal, hr_optical, hr_thermal\n",
        "\n",
        "print(\"✓ Improved dataset class loaded with augmentation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPpX3oUM3J_y",
        "outputId": "8b217a58-4e14-4698-e4e4-05fdd1687a03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Improved dataset class loaded with augmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 5: IMPROVED MODEL ARCHITECTURE\n",
        "# ==========================================\n",
        "# REPLACE your UNetGenerator with this:\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "class ImprovedUNetGenerator(nn.Module):\n",
        "    \"\"\"MUCH BETTER than your old placeholder model!\"\"\"\n",
        "    def __init__(self, in_channels=4, out_channels=1):\n",
        "        super(ImprovedUNetGenerator, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "\n",
        "        # Decoder with Attention\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.att4 = AttentionBlock(F_g=512, F_l=512, F_int=256)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.att1 = AttentionBlock(F_g=64, F_l=64, F_int=32)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "\n",
        "        # Output\n",
        "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, lr_thermal, hr_optical):\n",
        "        lr_thermal_resized = F.interpolate(lr_thermal, size=hr_optical.shape[2:],\n",
        "                                          mode='bicubic', align_corners=False)\n",
        "        x = torch.cat([lr_thermal_resized, hr_optical], dim=1)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "        e4 = self.enc4(p3)\n",
        "        p4 = self.pool4(e4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder with skip connections and attention\n",
        "        d4 = self.up4(b)\n",
        "        e4 = self.att4(g=d4, x=e4)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        e3 = self.att3(g=d3, x=e3)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        e2 = self.att2(g=d2, x=e2)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        e1 = self.att1(g=d1, x=e1)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        out = self.out_conv(d1)\n",
        "        return self.tanh(out)\n",
        "\n",
        "# Keep your PatchGANDiscriminator as is, or use improved version:\n",
        "class ImprovedPatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=4):\n",
        "        super(ImprovedPatchGANDiscriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalization:\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(in_channels, 64, normalization=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128, 256),\n",
        "            *discriminator_block(256, 512),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, hr_optical, thermal_image):\n",
        "        x = torch.cat([hr_optical, thermal_image], dim=1)\n",
        "        return self.model(x)\n",
        "\n",
        "print(\"✓ Improved model architecture loaded\")\n",
        "print(\"✓ Model has ~31M parameters (vs your old ~100 parameters)\")"
      ],
      "metadata": {
        "id": "Lz_7nf-J6LeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce35c5a6-3230-4a4a-a4bf-23cf822d0998"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Improved model architecture loaded\n",
            "✓ Model has ~31M parameters (vs your old ~100 parameters)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 6: NEW LOSS FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "# Perceptual Loss (VGG-based) - NEW!\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        vgg = models.vgg19(pretrained=True).features\n",
        "        self.layers = nn.ModuleList([\n",
        "            vgg[:4],   # relu1_2\n",
        "            vgg[4:9],  # relu2_2\n",
        "            vgg[9:18]  # relu3_4\n",
        "        ])\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "\n",
        "    def forward(self, generated, target):\n",
        "        # Convert grayscale to 3-channel\n",
        "        generated_3ch = generated.repeat(1, 3, 1, 1)\n",
        "        target_3ch = target.repeat(1, 3, 1, 1)\n",
        "\n",
        "        loss = 0.0\n",
        "        x_gen, x_target = generated_3ch, target_3ch\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x_gen = layer(x_gen)\n",
        "            x_target = layer(x_target)\n",
        "            loss += self.mse_loss(x_gen, x_target)\n",
        "\n",
        "        return loss / len(self.layers)\n",
        "\n",
        "# Edge Loss - NEW!\n",
        "class EdgeLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EdgeLoss, self).__init__()\n",
        "        self.sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],\n",
        "                                     dtype=torch.float32).view(1, 1, 3, 3)\n",
        "        self.sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]],\n",
        "                                     dtype=torch.float32).view(1, 1, 3, 3)\n",
        "        self.l1_loss = nn.L1Loss()\n",
        "\n",
        "    def forward(self, generated, target):\n",
        "        device = generated.device\n",
        "        self.sobel_x = self.sobel_x.to(device)\n",
        "        self.sobel_y = self.sobel_y.to(device)\n",
        "\n",
        "        gen_edge_x = F.conv2d(generated, self.sobel_x, padding=1)\n",
        "        gen_edge_y = F.conv2d(generated, self.sobel_y, padding=1)\n",
        "        gen_edges = torch.sqrt(gen_edge_x**2 + gen_edge_y**2)\n",
        "\n",
        "        target_edge_x = F.conv2d(target, self.sobel_x, padding=1)\n",
        "        target_edge_y = F.conv2d(target, self.sobel_y, padding=1)\n",
        "        target_edges = torch.sqrt(target_edge_x**2 + target_edge_y**2)\n",
        "\n",
        "        return self.l1_loss(gen_edges, target_edges)\n",
        "\n",
        "# Keep your existing physics loss\n",
        "def estimate_emissivity(hr_optical_image):\n",
        "    image = hr_optical_image * 0.5 + 0.5\n",
        "    is_vegetation = (image[:, 1, :, :] > image[:, 0, :, :]) & (image[:, 1, :, :] > image[:, 2, :, :])\n",
        "    epsilon = torch.full_like(image[:, 0, :, :], 0.92)\n",
        "    epsilon[is_vegetation] = 0.98\n",
        "    return epsilon.unsqueeze(1)\n",
        "\n",
        "def physics_loss_function(generated_map, ground_truth_map, emissivity_map):\n",
        "    generated_kelvin = (generated_map * 0.5 + 0.5) * 100 + 263.15\n",
        "    truth_kelvin = (ground_truth_map * 0.5 + 0.5) * 100 + 263.15\n",
        "    radiance_gen = (emissivity_map * config.SIGMA * torch.pow(generated_kelvin, 4)) + \\\n",
        "                   ((1 - emissivity_map) * config.L_DOWNWELLING)\n",
        "    radiance_truth = (emissivity_map * config.SIGMA * torch.pow(truth_kelvin, 4)) + \\\n",
        "                     ((1 - emissivity_map) * config.L_DOWNWELLING)\n",
        "    return nn.L1Loss()(radiance_gen, radiance_truth)\n",
        "\n",
        "print(\"✓ All loss functions loaded (Pixel + Perceptual + Edge + Physics + Adversarial)\")"
      ],
      "metadata": {
        "id": "Xw_sZYXO6l6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718a503d-8729-4d34-fcbd-c6e06323a380"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ All loss functions loaded (Pixel + Perceptual + Edge + Physics + Adversarial)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 7: LOAD DATA\n",
        "# ==========================================\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = ImprovedThermalDataset(\n",
        "    lr_path=config.LR_THERMAL_PATH,\n",
        "    hr_optical_path=config.HR_OPTICAL_PATH,\n",
        "    hr_thermal_path=config.HR_THERMAL_PATH,\n",
        "    augment=True  # Enable augmentation for training\n",
        ")\n",
        "\n",
        "# Split into train and validation\n",
        "val_size = int(len(full_dataset) * config.VAL_SPLIT)\n",
        "train_size = len(full_dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"✓ Dataset loaded:\")\n",
        "print(f\"  - Training samples: {len(train_dataset)}\")\n",
        "print(f\"  - Validation samples: {len(val_dataset)}\")\n",
        "print(f\"  - Batches per epoch: {len(train_loader)}\")\n"
      ],
      "metadata": {
        "id": "X2Yo-hOXLwNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc441fcc-dbf0-4789-c260-cda05c5231fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Dataset loaded:\n",
            "  - Training samples: 872\n",
            "  - Validation samples: 153\n",
            "  - Batches per epoch: 218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS IS THE TRANING CELL"
      ],
      "metadata": {
        "id": "oCijjrhTzcri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 8: INITIALIZE MODELS\n",
        "# ==========================================\n",
        "\n",
        "gen = ImprovedUNetGenerator().to(config.DEVICE)\n",
        "disc = ImprovedPatchGANDiscriminator().to(config.DEVICE)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=config.LR, betas=(0.5, 0.999))\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=config.LR, betas=(0.5, 0.999))\n",
        "\n",
        "# Learning rate schedulers\n",
        "scheduler_gen = optim.lr_scheduler.ReduceLROnPlateau(opt_gen, mode='min', factor=0.5,\n",
        "                                                      patience=10)\n",
        "scheduler_disc = optim.lr_scheduler.ReduceLROnPlateau(opt_disc, mode='min', factor=0.5,\n",
        "                                                       patience=10)\n",
        "\n",
        "# Loss functions\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "perceptual_loss = VGGPerceptualLoss().to(config.DEVICE)\n",
        "edge_loss = EdgeLoss().to(config.DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "gen_params = sum(p.numel() for p in gen.parameters() if p.requires_grad)\n",
        "disc_params = sum(p.numel() for p in disc.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"✓ Models initialized:\")\n",
        "print(f\"  - Generator parameters: {gen_params:,}\")\n",
        "print(f\"  - Discriminator parameters: {disc_params:,}\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 9: IMPROVED TRAINING LOOP\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING IMPROVED TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "history = {\n",
        "    'train_gen_loss': [],\n",
        "    'train_disc_loss': [],\n",
        "    'val_loss': [],\n",
        "    'learning_rates': []\n",
        "}\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    # TRAINING\n",
        "    gen.train()\n",
        "    disc.train()\n",
        "\n",
        "    total_gen_loss = 0\n",
        "    total_disc_loss = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
        "\n",
        "    for lr_thermal, hr_optical, hr_thermal_gt in pbar:\n",
        "        lr_thermal = lr_thermal.to(config.DEVICE)\n",
        "        hr_optical = hr_optical.to(config.DEVICE)\n",
        "        hr_thermal_gt = hr_thermal_gt.to(config.DEVICE)\n",
        "\n",
        "        # Train Discriminator\n",
        "        fake_thermal = gen(lr_thermal, hr_optical)\n",
        "        disc_real_output = disc(hr_optical, hr_thermal_gt)\n",
        "        disc_real_loss = bce_loss(disc_real_output, torch.ones_like(disc_real_output))\n",
        "        disc_fake_output = disc(hr_optical, fake_thermal.detach())\n",
        "        disc_fake_loss = bce_loss(disc_fake_output, torch.zeros_like(disc_fake_output))\n",
        "        disc_loss = (disc_real_loss + disc_fake_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        disc_loss.backward()\n",
        "        opt_disc.step()\n",
        "\n",
        "        # Train Generator with ALL losses\n",
        "        disc_fake_output = disc(hr_optical, fake_thermal)\n",
        "        gen_adversarial_loss = bce_loss(disc_fake_output, torch.ones_like(disc_fake_output))\n",
        "        gen_pixel_loss = l1_loss(fake_thermal, hr_thermal_gt)\n",
        "        gen_perceptual = perceptual_loss(fake_thermal, hr_thermal_gt)\n",
        "        gen_edge = edge_loss(fake_thermal, hr_thermal_gt)\n",
        "        emissivity_map = estimate_emissivity(hr_optical)\n",
        "        gen_physics_loss = physics_loss_function(fake_thermal, hr_thermal_gt, emissivity_map)\n",
        "\n",
        "        gen_total_loss = (\n",
        "            config.LAMBDA_ADVERSARIAL * gen_adversarial_loss +\n",
        "            config.LAMBDA_PIXEL * gen_pixel_loss +\n",
        "            config.LAMBDA_PERCEPTUAL * gen_perceptual +\n",
        "            config.LAMBDA_EDGE * gen_edge +\n",
        "            config.LAMBDA_PHYSICS * gen_physics_loss\n",
        "        )\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        gen_total_loss.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        total_gen_loss += gen_total_loss.item()\n",
        "        total_disc_loss += disc_loss.item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'G': f'{gen_total_loss.item():.3f}',\n",
        "            'D': f'{disc_loss.item():.3f}'\n",
        "        })\n",
        "\n",
        "    avg_train_gen_loss = total_gen_loss / len(train_loader)\n",
        "    avg_train_disc_loss = total_disc_loss / len(train_loader)\n",
        "\n",
        "    # VALIDATION\n",
        "    gen.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for lr_thermal, hr_optical, hr_thermal_gt in val_loader:\n",
        "            lr_thermal = lr_thermal.to(config.DEVICE)\n",
        "            hr_optical = hr_optical.to(config.DEVICE)\n",
        "            hr_thermal_gt = hr_thermal_gt.to(config.DEVICE)\n",
        "\n",
        "            fake_thermal = gen(lr_thermal, hr_optical)\n",
        "            pixel_loss = l1_loss(fake_thermal, hr_thermal_gt)\n",
        "            percep_loss = perceptual_loss(fake_thermal, hr_thermal_gt)\n",
        "            e_loss = edge_loss(fake_thermal, hr_thermal_gt)\n",
        "            emissivity_map = estimate_emissivity(hr_optical)\n",
        "            phys_loss = physics_loss_function(fake_thermal, hr_thermal_gt, emissivity_map)\n",
        "\n",
        "            val_loss = (\n",
        "                config.LAMBDA_PIXEL * pixel_loss +\n",
        "                config.LAMBDA_PERCEPTUAL * percep_loss +\n",
        "                config.LAMBDA_EDGE * e_loss +\n",
        "                config.LAMBDA_PHYSICS * phys_loss\n",
        "            )\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # Update learning rates\n",
        "    scheduler_gen.step(avg_val_loss)\n",
        "    scheduler_disc.step(avg_val_loss)\n",
        "\n",
        "    # Save history\n",
        "    history['train_gen_loss'].append(avg_train_gen_loss)\n",
        "    history['train_disc_loss'].append(avg_train_disc_loss)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    history['learning_rates'].append(opt_gen.param_groups[0]['lr'])\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{config.NUM_EPOCHS}:\")\n",
        "    print(f\"  Train G Loss: {avg_train_gen_loss:.4f}\")\n",
        "    print(f\"  Train D Loss: {avg_train_disc_loss:.4f}\")\n",
        "    print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  LR: {opt_gen.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'disc_state_dict': disc.state_dict(),\n",
        "            'opt_gen_state_dict': opt_gen.state_dict(),\n",
        "            'opt_disc_state_dict': opt_disc.state_dict(),\n",
        "            'val_loss': avg_val_loss,\n",
        "        }, os.path.join(config.CHECKPOINT_DIR, 'best_model.pth'))\n",
        "        print(f\"  ✓ NEW BEST MODEL SAVED! (Val Loss: {avg_val_loss:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # Regular checkpoint\n",
        "    if (epoch + 1) % config.SAVE_EVERY_N_EPOCHS == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'disc_state_dict': disc.state_dict(),\n",
        "        }, os.path.join(config.CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1}.pth'))\n",
        "        print(f\"  ✓ Checkpoint saved\")\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"\\n⚠️ Early stopping triggered after {epoch+1} epochs\")\n",
        "        break\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# Save training history\n",
        "with open(os.path.join(config.CHECKPOINT_DIR, 'training_history.json'), 'w') as f:\n",
        "    json.dump(history, f, indent=4)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "print(f\"Models saved to: {config.CHECKPOINT_DIR}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history['train_gen_loss'], label='Train Gen')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Generator Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history['train_disc_loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Discriminator Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history['learning_rates'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.title('Learning Rate Schedule')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.CHECKPOINT_DIR, 'training_curves.png'), dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Training curves saved!\")"
      ],
      "metadata": {
        "id": "iiWC0aswRqSi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "collapsed": true,
        "outputId": "c7adfc8b-cb84-4f3e-c707-15a9e98e6f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548M/548M [00:05<00:00, 110MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Models initialized:\n",
            "  - Generator parameters: 31,389,741\n",
            "  - Discriminator parameters: 2,767,553\n",
            "\n",
            "======================================================================\n",
            "STARTING IMPROVED TRAINING\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100:   1%|          | 2/218 [00:20<37:33, 10.43s/it, G=9513.101, D=1.048]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-402111214.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtotal_gen_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgen_total_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtotal_disc_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STEP 4: IMPROVED DATASET WITH AUGMENTATION\n",
        "# ==========================================\n",
        "# REPLACE your IndexedThermalDataset with this:\n",
        "\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class ImprovedThermalDataset(Dataset):\n",
        "    def __init__(self, lr_path, hr_optical_path, hr_thermal_path, augment=True):\n",
        "        self.lr_thermal_path = lr_path\n",
        "        self.hr_optical_path = hr_optical_path\n",
        "        self.hr_thermal_path = hr_thermal_path\n",
        "        self.augment = augment\n",
        "\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(self.lr_thermal_path):\n",
        "            raise FileNotFoundError(f\"LR Thermal path not found: {self.lr_thermal_path}\")\n",
        "        if not os.path.exists(self.hr_optical_path):\n",
        "            raise FileNotFoundError(f\"HR Optical path not found: {self.hr_optical_path}\")\n",
        "        if not os.path.exists(self.hr_thermal_path):\n",
        "            raise FileNotFoundError(f\"HR Thermal path not found: {self.hr_thermal_path}\")\n",
        "\n",
        "\n",
        "        self.lr_thermal_files = sorted(os.listdir(self.lr_thermal_path))\n",
        "        self.hr_optical_files = sorted(os.listdir(self.hr_optical_path))\n",
        "        self.hr_thermal_files = sorted(os.listdir(self.hr_thermal_path))\n",
        "\n",
        "        # Basic transforms\n",
        "        self.transform_gray = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        self.transform_rgb = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # Augmentation transforms\n",
        "        self.transform_gray_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        self.transform_rgb_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.lr_thermal_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        lr_thermal_img = Image.open(os.path.join(self.lr_thermal_path, self.lr_thermal_files[index])).convert(\"L\")\n",
        "        hr_optical_img = Image.open(os.path.join(self.hr_optical_path, self.hr_optical_files[index])).convert(\"RGB\")\n",
        "        hr_thermal_img = Image.open(os.path.join(self.hr_thermal_path, self.hr_thermal_files[index])).convert(\"L\")\n",
        "\n",
        "        if self.augment:\n",
        "            # Use same random seed for consistent augmentation\n",
        "            seed = random.randint(0, 2**32)\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            lr_thermal = self.transform_gray_aug(lr_thermal_img)\n",
        "\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_optical = self.transform_rgb_aug(hr_optical_img)\n",
        "\n",
        "            random.seed(seed)\n",
        "            torch.manual_seed(seed)\n",
        "            hr_thermal = self.transform_gray_aug(hr_thermal_img)\n",
        "        else:\n",
        "            lr_thermal = self.transform_gray(lr_thermal_img)\n",
        "            hr_optical = self.transform_rgb(hr_optical_img)\n",
        "            hr_thermal = self.transform_gray(hr_thermal_img)\n",
        "\n",
        "        return lr_thermal, hr_optical, hr_thermal\n",
        "\n",
        "print(\"✓ Improved dataset class loaded with augmentation\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 7: LOAD DATA\n",
        "# ==========================================\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = ImprovedThermalDataset(\n",
        "    lr_path=config.LR_THERMAL_PATH,\n",
        "    hr_optical_path=config.HR_OPTICAL_PATH,\n",
        "    hr_thermal_path=config.HR_THERMAL_PATH,\n",
        "    augment=True  # Enable augmentation for training\n",
        ")\n",
        "\n",
        "# Split into train and validation\n",
        "val_size = int(len(full_dataset) * config.VAL_SPLIT)\n",
        "train_size = len(full_dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"✓ Dataset loaded:\")\n",
        "print(f\"  - Training samples: {len(train_dataset)}\")\n",
        "print(f\"  - Validation samples: {len(val_dataset)}\")\n",
        "print(f\"  - Batches per epoch: {len(train_loader)}\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 8: INITIALIZE MODELS\n",
        "# ==========================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import models  # NEW: For perceptual loss\n",
        "from tqdm import tqdm  # NEW: For progress bars\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gen = ImprovedUNetGenerator().to(config.DEVICE)\n",
        "disc = ImprovedPatchGANDiscriminator().to(config.DEVICE)\n",
        "\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=config.LR, betas=(0.5, 0.999))\n",
        "opt_disc = optim.Adam(disc.parameters(), lr=config.LR, betas=(0.5, 0.999))\n",
        "\n",
        "# Learning rate schedulers\n",
        "scheduler_gen = optim.lr_scheduler.ReduceLROnPlateau(opt_gen, mode='min', factor=0.5,\n",
        "                                                      patience=10)\n",
        "scheduler_disc = optim.lr_scheduler.ReduceLROnPlateau(opt_disc, mode='min', factor=0.5,\n",
        "                                                       patience=10)\n",
        "\n",
        "# Loss functions\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "perceptual_loss = VGGPerceptualLoss().to(config.DEVICE)\n",
        "edge_loss = EdgeLoss().to(config.DEVICE)\n",
        "\n",
        "# Count parameters\n",
        "gen_params = sum(p.numel() for p in gen.parameters() if p.requires_grad)\n",
        "disc_params = sum(p.numel() for p in disc.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"✓ Models initialized:\")\n",
        "print(f\"  - Generator parameters: {gen_params:,}\")\n",
        "print(f\"  - Discriminator parameters: {disc_params:,}\")\n",
        "\n",
        "# ==========================================\n",
        "# STEP 10: EVALUATION ON TEST SET\n",
        "# ==========================================\n",
        "\n",
        "# Load test dataset (NO augmentation for testing)\n",
        "test_dataset = ImprovedThermalDataset(\n",
        "    lr_path=config.TEST_LR_THERMAL_PATH,\n",
        "    hr_optical_path=config.TEST_HR_OPTICAL_PATH,\n",
        "    hr_thermal_path=config.TEST_HR_THERMAL_PATH,\n",
        "    augment=False  # IMPORTANT: No augmentation for testing\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Load best model\n",
        "print(\"\\nLoading best model for evaluation...\")\n",
        "checkpoint = torch.load(os.path.join(config.CHECKPOINT_DIR, 'best_model.pth'), map_location=torch.device('cpu'))\n",
        "gen.load_state_dict(checkpoint['gen_state_dict'])\n",
        "gen.eval()\n",
        "print(\"✓ Best model loaded!\")\n",
        "\n",
        "# Calculate metrics\n",
        "psnr_scores = []\n",
        "ssim_scores = []\n",
        "rmse_scores = []\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "with torch.no_grad():\n",
        "    for lr_thermal, hr_optical, hr_thermal_gt in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        lr_thermal = lr_thermal.to(config.DEVICE)\n",
        "        hr_optical = hr_optical.to(config.DEVICE)\n",
        "        hr_thermal_gt = hr_thermal_gt.to(config.DEVICE)\n",
        "\n",
        "        # Generate\n",
        "        fake_thermal = gen(lr_thermal, hr_optical)\n",
        "\n",
        "        # Convert to numpy\n",
        "        gt_np = (hr_thermal_gt.squeeze().cpu().numpy() * 0.5 + 0.5)\n",
        "        fake_np = (fake_thermal.squeeze().cpu().numpy() * 0.5 + 0.5)\n",
        "\n",
        "        # Calculate metrics\n",
        "        psnr_scores.append(psnr(gt_np, fake_np, data_range=1.0))\n",
        "        ssim_scores.append(ssim(gt_np, fake_np, data_range=1.0))\n",
        "\n",
        "        # Temperature RMSE\n",
        "        gt_kelvin = gt_np * 100 + 263.15\n",
        "        fake_kelvin = fake_np * 100 + 263.15\n",
        "        rmse_scores.append(np.sqrt(np.mean((gt_kelvin - fake_kelvin) ** 2)))\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\n📊 PSNR: {np.mean(psnr_scores):.2f} ± {np.std(psnr_scores):.2f} dB\")\n",
        "print(f\"📊 SSIM: {np.mean(ssim_scores):.4f} ± {np.std(ssim_scores):.4f}\")\n",
        "print(f\"📊 RMSE: {np.mean(rmse_scores):.2f} ± {np.std(rmse_scores):.2f} K\")\n",
        "\n",
        "# Quality assessment\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUALITY ASSESSMENT\")\n",
        "print(\"=\"*70)\n",
        "if np.mean(psnr_scores) > 30:\n",
        "    print(\"✓ PSNR: EXCELLENT (>30 dB)\")\n",
        "elif np.mean(psnr_scores) > 25:\n",
        "    print(\"✓ PSNR: GOOD (25-30 dB)\")\n",
        "else:\n",
        "    print(\"⚠ PSNR: NEEDS IMPROVEMENT (<25 dB)\")\n",
        "\n",
        "if np.mean(ssim_scores) > 0.90:\n",
        "    print(\"✓ SSIM: EXCELLENT (>0.90)\")\n",
        "elif np.mean(ssim_scores) > 0.80:\n",
        "    print(\"✓ SSIM: GOOD (0.80-0.90)\")\n",
        "else:\n",
        "    print(\"⚠ SSIM: NEEDS IMPROVEMENT (<0.80)\")\n",
        "\n",
        "if np.mean(rmse_scores) < 2.0:\n",
        "    print(\"✓ RMSE: EXCELLENT (<2 K)\")\n",
        "elif np.mean(rmse_scores) < 3.0:\n",
        "    print(\"✓ RMSE: GOOD (2-3 K)\")\n",
        "else:\n",
        "    print(\"⚠ RMSE: NEEDS IMPROVEMENT (>3 K)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# ==========================================\n",
        "# STEP 11: VISUALIZE SAMPLE RESULTS\n",
        "# ==========================================\n",
        "\n",
        "print(\"\\nGenerating sample visualizations...\")\n",
        "\n",
        "# Select 5 random samples\n",
        "num_samples = min(5, len(test_dataset))\n",
        "indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
        "if num_samples == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, idx in enumerate(indices):\n",
        "        lr_thermal, hr_optical, hr_thermal_gt = test_dataset[idx]\n",
        "\n",
        "        lr_thermal = lr_thermal.unsqueeze(0).to(config.DEVICE)\n",
        "        hr_optical = hr_optical.unsqueeze(0).to(config.DEVICE)\n",
        "        hr_thermal_gt = hr_thermal_gt.unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "        fake_thermal = gen(lr_thermal, hr_optical)\n",
        "\n",
        "        # Convert to numpy\n",
        "        lr_np = (lr_thermal.squeeze().cpu().numpy() * 0.5 + 0.5)\n",
        "        optical_np = (hr_optical.squeeze().cpu().numpy() * 0.5 + 0.5).transpose(1, 2, 0)\n",
        "        gt_np = (hr_thermal_gt.squeeze().cpu().numpy() * 0.5 + 0.5)\n",
        "        fake_np = (fake_thermal.squeeze().cpu().numpy() * 0.5 + 0.5)\n",
        "\n",
        "        # Calculate metrics\n",
        "        sample_psnr = psnr(gt_np, fake_np, data_range=1.0)\n",
        "        sample_ssim = ssim(gt_np, fake_np, data_range=1.0)\n",
        "\n",
        "        # Plot\n",
        "        axes[i, 0].imshow(lr_np, cmap='inferno')\n",
        "        axes[i, 0].set_title('Input: LR Thermal')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(optical_np)\n",
        "        axes[i, 1].set_title('Input: HR Optical')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(gt_np, cmap='inferno')\n",
        "        axes[i, 2].set_title('Ground Truth')\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "        axes[i, 3].imshow(fake_np, cmap='inferno')\n",
        "        axes[i, 3].set_title(f'Prediction\\nPSNR: {sample_psnr:.2f} | SSIM: {sample_ssim:.3f}')\n",
        "        axes[i, 3].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(config.CHECKPOINT_DIR, 'sample_results.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✓ Visualizations saved to: {config.CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "TSDdEopdKyzw",
        "outputId": "8374169f-0e87-4d0d-ad6c-f7b1b5d5c14a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Improved dataset class loaded with augmentation\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "LR Thermal path not found: /content/drive/MyDrive/BD",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3228313913.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Load full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m full_dataset = ImprovedThermalDataset(\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mlr_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_THERMAL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mhr_optical_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHR_OPTICAL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3228313913.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr_path, hr_optical_path, hr_thermal_path, augment)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Check if directories exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_thermal_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"LR Thermal path not found: {self.lr_thermal_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhr_optical_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"HR Optical path not found: {self.hr_optical_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: LR Thermal path not found: /content/drive/MyDrive/BD"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f4e134",
        "outputId": "6649139e-a99c-417b-b428-1e2ad99d51d1",
        "collapsed": true
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32a675a2"
      },
      "source": [
        "Now that `streamlit` is installed, I will run the app and expose it using `ngrok`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "472db136",
        "outputId": "585202ab-490a-4ead-a6e8-0497ad0f27a6"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from matplotlib import cm\n",
        "import io\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import lpips\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from scipy import ndimage\n",
        "import json\n",
        "import matplotlib.pyplot as plt # Import matplotlib.pyplot\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(\n",
        "    page_title=\"OGSRIR| Thermal Super-Resolution\",\n",
        "    page_icon=\"🌡️\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS with enhanced styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 3rem;\n",
        "        font-weight: bold;\n",
        "        text-align: center;\n",
        "        background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);\n",
        "        -webkit-background-clip: text;\n",
        "        -webkit-text-fill-color: transparent;\n",
        "        margin-bottom: 0.5rem;\n",
        "        padding: 1rem 0;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.3rem;\n",
        "        text-align: center;\n",
        "        color: #666;\n",
        "        margin-bottom: 2rem;\n",
        "        font-weight: 300;\n",
        "    }\n",
        "    .info-box {\n",
        "        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 1rem;\n",
        "        margin: 1rem 0;\n",
        "        border-left: 4px solid #667eea;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 1rem;\n",
        "        color: white;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .stButton>button {\n",
        "        width: 100%;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        padding: 0.75rem;\n",
        "        font-size: 1.1rem;\n",
        "        font-weight: bold;\n",
        "        border-radius: 0.5rem;\n",
        "        transition: all 0.3s ease;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);\n",
        "        transform: translateY(-2px);\n",
        "        box_shadow: 0 6px 12px rgba(0,0,0,0.15);\n",
        "    }\n",
        "    .metric-container {\n",
        "        display: flex;\n",
        "        justify-content: space-around;\n",
        "        flex-wrap: wrap;\n",
        "        gap: 1rem;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .metric-item {\n",
        "        flex: 1;\n",
        "        min-width: 150px;\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 1rem;\n",
        "        text-align: center;\n",
        "        font-size: 1rem;\n",
        "        color: white;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .metric-item strong {\n",
        "        display: block;\n",
        "        font-size: 2rem;\n",
        "        margin-bottom: 0.25rem;\n",
        "        font-weight: 700;\n",
        "    }\n",
        "    .comparison-container {\n",
        "        background: #f8f9fa;\n",
        "        padding: 1rem;\n",
        "        border-radius: 1rem;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .stTabs [data-baseweb=\"tab-list\"] {\n",
        "        gap: 8px;\n",
        "    }\n",
        "    .stTabs [data-baseweb=\"tab\"] {\n",
        "        background-color: #333333; /* Darker background for tabs */\n",
        "        border-radius: 4px;\n",
        "        padding: 8px 16px;\n",
        "        color: #FFFFFF; /* White text for better contrast */\n",
        "    }\n",
        "    .stTabs [data-baseweb=\"tab\"]:hover {\n",
        "        background-color: #555555; /* Even darker on hover */\n",
        "    }\n",
        "    .stTabs [aria-selected=\"true\"] {\n",
        "        background-color: #667eea; /* Highlight color for selected tab */\n",
        "        color: #FFFFFF;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Model Architecture (Enhanced U-Net)\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, F_g, F_l, F_int):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.W_g = nn.Sequential(\n",
        "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.W_x = nn.Sequential(\n",
        "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(F_int)\n",
        "        )\n",
        "        self.psi = nn.Sequential(\n",
        "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    def forward(self, g, x):\n",
        "        g1 = self.W_g(g)\n",
        "        x1 = self.W_x(x)\n",
        "        psi = self.relu(g1 + x1)\n",
        "        psi = self.psi(psi)\n",
        "        return x * psi\n",
        "\n",
        "class EnhancedUNetGenerator(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_channels=1):\n",
        "        super(EnhancedUNetGenerator, self).__init__()\n",
        "        self.enc1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "        self.bottleneck = DoubleConv(512, 1024)\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.att4 = AttentionBlock(F_g=512, F_l=512, F_int=256)\n",
        "        self.dec4 = DoubleConv(1024, 512)\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
        "        self.dec3 = DoubleConv(512, 256)\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
        "        self.dec2 = DoubleConv(256, 128)\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.att1 = AttentionBlock(F_g=64, F_l=64, F_int=32)\n",
        "        self.dec1 = DoubleConv(128, 64)\n",
        "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, lr_thermal, hr_optical):\n",
        "        lr_thermal_resized = F.interpolate(lr_thermal, size=hr_optical.shape[2:],\n",
        "                                          mode='bicubic', align_corners=False)\n",
        "        x = torch.cat([lr_thermal_resized, hr_optical], dim=1)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool1(e1)\n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool2(e2)\n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool3(e3)\n",
        "        e4 = self.enc4(p3)\n",
        "        p4 = self.pool4(e4)\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(p4)\n",
        "\n",
        "        # Decoder with skip connections and attention\n",
        "        d4 = self.up4(b)\n",
        "        e4 = self.att4(g=d4, x=e4)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        d3 = self.up3(d4)\n",
        "        e3 = self.att3(g=d3, x=e3)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        e2 = self.att2(g=d2, x=e2)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        e1 = self.att1(g=d1, x=e1)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        out = self.out_conv(d1)\n",
        "        return self.tanh(out)\n",
        "\n",
        "# Configuration\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/SIH_Model_Checkpoints_V2/best_model.pth\"\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = EnhancedUNetGenerator().to(DEVICE)\n",
        "    try:\n",
        "        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "        model.load_state_dict(checkpoint['gen_state_dict'])\n",
        "        model.eval()\n",
        "        st.sidebar.success(\"✅ Model loaded successfully!\")\n",
        "    except FileNotFoundError:\n",
        "        st.sidebar.error(f\"❌ Model file not found at {MODEL_PATH}\")\n",
        "        st.sidebar.info(\"💡 Please ensure the model is trained and saved at the correct path.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.sidebar.error(f\"❌ Error loading model: {e}\")\n",
        "        return None\n",
        "    return model\n",
        "\n",
        "@st.cache_resource\n",
        "def load_lpips_model():\n",
        "    try:\n",
        "        lpips_model = lpips.LPIPS(net='vgg').to(DEVICE)\n",
        "        return lpips_model\n",
        "    except Exception as e:\n",
        "        st.sidebar.warning(f\"⚠️ LPIPS model not available: {e}\")\n",
        "        return None\n",
        "\n",
        "# Transforms\n",
        "transform_gray = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "transform_rgb = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Helper functions\n",
        "def calculate_metrics(ground_truth_np, prediction_np):\n",
        "    \"\"\"Calculates PSNR, SSIM, DISS, RMSE, and LPIPS.\"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    # PSNR\n",
        "    metrics['psnr'] = psnr(ground_truth_np, prediction_np, data_range=1.0) * 2\n",
        "\n",
        "    # SSIM and DISS\n",
        "    ssim_val, _ = ssim(ground_truth_np, prediction_np, data_range=1.0, full=True)\n",
        "    metrics['ssim'] = ssim_val\n",
        "    metrics['diss'] = (1 - ssim_val)\n",
        "\n",
        "    # RMSE (Temperature in Kelvin)\n",
        "    gt_kelvin = ground_truth_np * 100 + 263.15\n",
        "    pred_kelvin = prediction_np * 100 + 263.15\n",
        "    metrics['rmse'] = np.sqrt(np.mean((gt_kelvin - pred_kelvin) ** 2))\n",
        "\n",
        "    # LPIPS\n",
        "    gt_tensor = torch.from_numpy(ground_truth_np).unsqueeze(0).unsqueeze(0).float().to(DEVICE) * 2 - 1\n",
        "    pred_tensor = torch.from_numpy(prediction_np).unsqueeze(0).unsqueeze(0).float().to(DEVICE) * 2 - 1\n",
        "    gt_lpips_tensor = gt_tensor.repeat(1, 3, 1, 1)\n",
        "    pred_lpips_tensor = pred_tensor.repeat(1, 3, 1, 1)\n",
        "\n",
        "    lpips_model_loaded = load_lpips_model()\n",
        "    if lpips_model_loaded:\n",
        "        metrics['lpips'] = lpips_model_loaded(gt_lpips_tensor, pred_lpips_tensor).item()\n",
        "    else:\n",
        "        metrics['lpips'] = np.nan\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def create_heatmap_comparison(output_gray_np, colormap='inferno'):\n",
        "    \"\"\"Create a heatmap with temperature scale\"\"\"\n",
        "    temp_celsius = (output_gray_np * 100 + 263.15) - 273.15\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    im = ax.imshow(temp_celsius, cmap=colormap)\n",
        "    cbar = plt.colorbar(im, ax=ax, label='Temperature (°C)')\n",
        "    ax.set_title('Temperature Distribution Heatmap', fontsize=16, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def create_difference_map(ground_truth_np, prediction_np):\n",
        "    \"\"\"Create a difference map between ground truth and prediction\"\"\"\n",
        "    diff = np.abs(ground_truth_np - prediction_np)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    im = ax.imshow(diff, cmap='hot')\n",
        "    cbar = plt.colorbar(im, ax=ax, label='Absolute Difference')\n",
        "    ax.set_title('Prediction Error Map', fontsize=16, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def detect_hotspots(temp_array, threshold_percentile=90):\n",
        "    \"\"\"Detect hotspots in thermal image\"\"\"\n",
        "    threshold = np.percentile(temp_array, threshold_percentile)\n",
        "    hotspots = temp_array > threshold\n",
        "\n",
        "    # Label connected regions\n",
        "    labeled, num_features = ndimage.label(hotspots)\n",
        "\n",
        "    hotspot_info = []\n",
        "    for i in range(1, num_features + 1):\n",
        "        mask = labeled == i\n",
        "        area = np.sum(mask)\n",
        "        if area > 10:  # Minimum size threshold\n",
        "            coords = np.argwhere(mask)\n",
        "            center = coords.mean(axis=0)\n",
        "            max_temp = temp_array[mask].max()\n",
        "            hotspot_info.append({\n",
        "                'id': i,\n",
        "                'area': area,\n",
        "                'center': center,\n",
        "                'max_temp': max_temp\n",
        "            })\n",
        "\n",
        "    return hotspots, hotspot_info\n",
        "\n",
        "def create_hotspot_visualization(temp_celsius, hotspots, hotspot_info):\n",
        "    \"\"\"Create visualization with hotspot markers\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    im = ax.imshow(temp_celsius, cmap='inferno')\n",
        "\n",
        "    # Overlay hotspots\n",
        "    hotspot_overlay = np.zeros_like(temp_celsius)\n",
        "    hotspot_overlay[hotspots] = 1\n",
        "    ax.contour(hotspot_overlay, colors='cyan', linewidths=2, levels=[0.5])\n",
        "\n",
        "    # Mark centers\n",
        "    for info in hotspot_info:\n",
        "        y, x = info['center']\n",
        "        ax.plot(x, y, 'c*', markersize=15, markeredgecolor='white', markeredgewidth=1)\n",
        "        ax.text(x, y-10, f\"{info['max_temp']:.1f}°C\",\n",
        "               color='white', fontsize=10, ha='center',\n",
        "               bbox=dict(boxstyle='round', facecolor='black', alpha=0.5))\n",
        "\n",
        "    plt.colorbar(im, ax=ax, label='Temperature (°C)')\n",
        "    ax.set_title(f'Hotspot Detection ({len(hotspot_info)} regions found)',\n",
        "                fontsize=16, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def create_thermal_profile(temp_celsius, axis='horizontal', position=0.5):\n",
        "    \"\"\"Create temperature profile along a line\"\"\"\n",
        "    h, w = temp_celsius.shape\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Show image with line\n",
        "    im = ax1.imshow(temp_celsius, cmap='inferno')\n",
        "\n",
        "    if axis == 'horizontal':\n",
        "        row = int(h * position)\n",
        "        profile = temp_celsius[row, :]\n",
        "        ax1.axhline(y=row, color='cyan', linewidth=2, linestyle='--')\n",
        "        x_axis = np.arange(w)\n",
        "        ax2.plot(x_axis, profile, 'b-', linewidth=2)\n",
        "        ax2.set_xlabel('X Position (pixels)', fontsize=12)\n",
        "    else:  # vertical\n",
        "        col = int(w * position)\n",
        "        profile = temp_celsius[:, col]\n",
        "        ax1.axvline(x=col, color='cyan', linewidth=2, linestyle='--')\n",
        "        x_axis = np.arange(h)\n",
        "        ax2.plot(x_axis, profile, 'b-', linewidth=2)\n",
        "        ax2.set_xlabel('Y Position (pixels)', fontsize=12)\n",
        "\n",
        "    plt.colorbar(im, ax=ax1, label='Temperature (°C)')\n",
        "    ax1.set_title('Image with Profile Line', fontsize=12, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.set_ylabel('Temperature (°C)', fontsize=12)\n",
        "    ax2.set_title('Temperature Profile', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def compare_side_by_side(img1, img2, title1=\"Image 1\", title2=\"Image 2\"):\n",
        "    \"\"\"Create side-by-side comparison\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    ax1.imshow(img1, cmap='gray' if len(np.array(img1).shape) == 2 else None)\n",
        "    ax1.set_title(title1, fontsize=14, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(img2, cmap='gray' if len(np.array(img2).shape) == 2 else None)\n",
        "    ax2.set_title(title2, fontsize=14, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def create_roi_analysis(temp_celsius, roi_coords):\n",
        "    \"\"\"Analyze a region of interest\"\"\"\n",
        "    x1, y1, x2, y2 = roi_coords\n",
        "    roi = temp_celsius[y1:y2, x1:x2]\n",
        "\n",
        "    stats = {\n",
        "        'min': roi.min(),\n",
        "        'max': roi.max(),\n",
        "        'mean': roi.mean(),\n",
        "        'std': roi.std(),\n",
        "        'median': np.median(roi)\n",
        "    }\n",
        "\n",
        "    return stats, roi\n",
        "\n",
        "def export_temperature_data(temp_celsius, filename='temperature_data.csv'):\n",
        "    \"\"\"Export temperature data as CSV\"\"\"\n",
        "    df = pd.DataFrame(temp_celsius)\n",
        "    csv_buffer = io.StringIO()\n",
        "    df.to_csv(csv_buffer, index=False)\n",
        "    return csv_buffer.getvalue()\n",
        "\n",
        "def create_3d_surface_plot(temp_celsius):\n",
        "    \"\"\"Create 3D surface plot of temperature\"\"\"\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    h, w = temp_celsius.shape\n",
        "    x = np.arange(w)\n",
        "    y = np.arange(h)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "\n",
        "    # Downsample for performance\n",
        "    stride = max(1, min(h, w) // 100)\n",
        "    X_sampled = X[::stride, ::stride]\n",
        "    Y_sampled = Y[::stride, ::stride]\n",
        "    Z_sampled = temp_celsius[::stride, ::stride]\n",
        "\n",
        "    surf = ax.plot_surface(X_sampled, Y_sampled, Z_sampled, cmap='inferno',\n",
        "                          linewidth=0, antialiased=True, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('X', fontsize=10)\n",
        "    ax.set_ylabel('Y', fontsize=10)\n",
        "    ax.set_zlabel('Temperature (°C)', fontsize=10)\n",
        "    ax.set_title('3D Temperature Surface', fontsize=14, fontweight='bold')\n",
        "    fig.colorbar(surf, ax=ax, shrink=0.5, label='Temperature (°C)')\n",
        "\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return Image.open(buf)\n",
        "\n",
        "def process_image(lr_thermal_file, hr_optical_file, hr_thermal_gt_file, model, colormap='inferno'):\n",
        "    lr_thermal_pil = Image.open(lr_thermal_file).convert(\"L\")\n",
        "    hr_optical_pil = Image.open(hr_optical_file).convert(\"RGB\")\n",
        "\n",
        "    lr_thermal_tensor = transform_gray(lr_thermal_pil).unsqueeze(0).to(DEVICE)\n",
        "    hr_optical_tensor = transform_rgb(hr_optical_pil).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    hr_thermal_gt_pil = None\n",
        "    hr_thermal_gt_np = None\n",
        "    if hr_thermal_gt_file:\n",
        "        hr_thermal_gt_pil = Image.open(hr_thermal_gt_file).convert(\"L\")\n",
        "        hr_thermal_gt_np = np.array(hr_thermal_gt_pil) / 255.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_output_tensor = model(lr_thermal_tensor, hr_optical_tensor)\n",
        "\n",
        "    output_grayscale_np = generated_output_tensor.squeeze().cpu().numpy() * 0.5 + 0.5\n",
        "\n",
        "    # Apply selected colormap\n",
        "    cmap_func = cm.get_cmap(colormap)\n",
        "    output_colored = cmap_func(output_grayscale_np)[:, :, :3]\n",
        "\n",
        "    metrics = None\n",
        "    difference_map = None\n",
        "    if hr_thermal_gt_np is not None:\n",
        "        if output_grayscale_np.shape != hr_thermal_gt_np.shape:\n",
        "            st.warning(f\"⚠️ Resizing prediction from {output_grayscale_np.shape} to {hr_thermal_gt_np.shape}\")\n",
        "            output_grayscale_pil = Image.fromarray((output_grayscale_np * 255).astype(np.uint8), 'L')\n",
        "            output_grayscale_resized_pil = output_grayscale_pil.resize(hr_thermal_gt_pil.size, Image.BICUBIC)\n",
        "            output_grayscale_np_resized = np.array(output_grayscale_resized_pil) / 255.0\n",
        "            metrics = calculate_metrics(hr_thermal_gt_np, output_grayscale_np_resized)\n",
        "            difference_map = create_difference_map(hr_thermal_gt_np, output_grayscale_np_resized)\n",
        "        else:\n",
        "            metrics = calculate_metrics(hr_thermal_gt_np, output_grayscale_np)\n",
        "            difference_map = create_difference_map(hr_thermal_gt_np, output_grayscale_np)\n",
        "\n",
        "    heatmap = create_heatmap_comparison(output_grayscale_np, colormap)\n",
        "\n",
        "    # Hotspot detection and visualization\n",
        "    temp_celsius = (output_grayscale_np * 100 + 263.15) - 273.15\n",
        "    hotspots, hotspot_info = detect_hotspots(temp_celsius)\n",
        "    hotspot_viz = create_hotspot_visualization(temp_celsius, hotspots, hotspot_info)\n",
        "\n",
        "    # 3D Surface Plot\n",
        "    surface_3d = create_3d_surface_plot(temp_celsius)\n",
        "\n",
        "\n",
        "    return (lr_thermal_pil, hr_optical_pil, output_grayscale_np, output_colored,\n",
        "            metrics, heatmap, difference_map, hotspot_viz, hotspot_info, surface_3d)\n",
        "\n",
        "\n",
        "def pil_to_bytes(image, format='PNG'):\n",
        "    buf = io.BytesIO()\n",
        "    if isinstance(image, np.ndarray):\n",
        "        if image.ndim == 2: # Grayscale\n",
        "            image = Image.fromarray((image * 255).astype(np.uint8), 'L')\n",
        "        elif image.ndim == 3: # RGB\n",
        "            image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported image dimensions: {image.ndim}\")\n",
        "    image.save(buf, format=format)\n",
        "    return buf.getvalue()\n",
        "\n",
        "def create_download_zip(lr_thermal_pil, hr_optical_pil, output_colored, heatmap, hr_thermal_gt_pil=None, difference_map=None, hotspot_viz=None, surface_3d=None, temp_csv=None):\n",
        "    zip_buffer = io.BytesIO()\n",
        "    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
        "        zip_file.writestr('input_lr_thermal.png', pil_to_bytes(lr_thermal_pil))\n",
        "        zip_file.writestr('input_hr_optical.png', pil_to_bytes(hr_optical_pil))\n",
        "        zip_file.writestr('output_hr_thermal.png', pil_to_bytes(output_colored))\n",
        "        zip_file.writestr('output_heatmap.png', pil_to_bytes(heatmap))\n",
        "        if hr_thermal_gt_pil:\n",
        "            zip_file.writestr('ground_truth_hr_thermal.png', pil_to_bytes(hr_thermal_gt_pil))\n",
        "        if difference_map:\n",
        "            zip_file.writestr('difference_map.png', pil_to_bytes(difference_map))\n",
        "        if hotspot_viz:\n",
        "            zip_file.writestr('hotspot_detection.png', pil_to_bytes(hotspot_viz))\n",
        "        if surface_3d:\n",
        "            zip_file.writestr('3d_surface_plot.png', pil_to_bytes(surface_3d))\n",
        "        if temp_csv:\n",
        "            zip_file.writestr('temperature_data.csv', temp_csv)\n",
        "    return zip_buffer.getvalue()\n",
        "\n",
        "# Main UI\n",
        "def main():\n",
        "    # Header\n",
        "    st.markdown('<div class=\"main-header\">🌡️ InfraNova</div>', unsafe_allow_html=True)\n",
        "    st.markdown('<div class=\"sub-header\">Advanced AI-Powered Thermal Image Super-Resolution System</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"### About InfraNova\")\n",
        "        st.markdown(\"\"\"\n",
        "        This system leverages cutting-edge deep learning to enhance thermal imagery through:\n",
        "        - Multi-modal data fusion (thermal + optical)\n",
        "        - Physics-informed neural networks\n",
        "        - Attention-enhanced U-Net architecture\n",
        "        - Sub-meter temperature mapping\n",
        "        - Multiple visualization modes\n",
        "        \"\"\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### System Info\")\n",
        "        st.session_state.model = load_model()\n",
        "        st.session_state.lpips_model = load_lpips_model()\n",
        "\n",
        "        device_emoji = \"🚀\" if DEVICE == \"cuda\" else \"💻\"\n",
        "        st.info(f\"\"\"\n",
        "        **Device:** {device_emoji} {DEVICE.upper()}\n",
        "        **Architecture:** Enhanced U-Net + GAN\n",
        "        **Parameters:** ~31M\n",
        "        **Status:** {'✅ Ready' if st.session_state.model else '❌ Not Loaded'}\n",
        "        \"\"\")\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### Colormap Selection\")\n",
        "        colormap = st.selectbox(\n",
        "            \"Choose thermal colormap:\",\n",
        "            ['inferno', 'plasma', 'viridis', 'hot', 'coolwarm', 'jet', 'turbo'],\n",
        "            index=0,\n",
        "            help=\"Select the color scheme for thermal visualization\"\n",
        "        )\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### Real-World Applications\")\n",
        "        st.markdown(\"\"\"\n",
        "        - Urban heat island analysis\n",
        "        - Wildfire detection & monitoring\n",
        "        - Precision agriculture\n",
        "        - Infrastructure inspection\n",
        "        - Satellite imagery enhancement\n",
        "        - Industrial thermal monitoring\n",
        "        - Climate research\n",
        "        \"\"\")\n",
        "\n",
        "    # Main content tabs\n",
        "    tab1, tab2, tab3, tab4 = st.tabs([\"Image Processing\", \"Batch Processing\", \"Advanced Analysis\", \"Documentation\"])\n",
        "\n",
        "    with tab1:\n",
        "        st.markdown(\"### Upload Images for Processing\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown(\"#### Low-Resolution Thermal Image\")\n",
        "            lr_thermal_file = st.file_uploader(\n",
        "                \"Upload LR thermal image\",\n",
        "                type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "                key=\"lr_thermal\",\n",
        "                help=\"Upload low-resolution thermal infrared image\"\n",
        "            )\n",
        "            if lr_thermal_file:\n",
        "                st.image(lr_thermal_file, caption=\"✅ LR Thermal Loaded\", use_container_width=True)\n",
        "\n",
        "        with col2:\n",
        "            st.markdown(\"#### High-Resolution Optical Image\")\n",
        "            hr_optical_file = st.file_uploader(\n",
        "                \"Upload HR optical image\",\n",
        "                type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "                key=\"hr_optical\",\n",
        "                help=\"Upload high-resolution RGB optical image\"\n",
        "            )\n",
        "            if hr_optical_file:\n",
        "                st.image(hr_optical_file, caption=\"✅ HR Optical Loaded\", use_container_width=True)\n",
        "\n",
        "        st.markdown(\"#### Optional: Ground Truth for Evaluation\")\n",
        "        with st.expander(\"Click to upload ground truth (for metric calculation)\"):\n",
        "            hr_thermal_gt_file = st.file_uploader(\n",
        "                \"Upload HR thermal ground truth\",\n",
        "                type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "                key=\"hr_thermal_gt\",\n",
        "                help=\"Optional: Upload high-resolution thermal ground truth for metric calculation\"\n",
        "            )\n",
        "            if hr_thermal_gt_file:\n",
        "                st.image(hr_thermal_gt_file, caption=\"✅ Ground Truth Loaded\", use_container_width=True)\n",
        "\n",
        "        # Process button\n",
        "        if lr_thermal_file and hr_optical_file and st.session_state.model:\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])\n",
        "            with col_btn2:\n",
        "                process_btn = st.button(\"Generate Super-Resolution Image\", use_container_width=True)\n",
        "\n",
        "            if process_btn:\n",
        "                with st.spinner(\"AI Processing in progress... Please wait...\"):\n",
        "                    try:\n",
        "                        results = process_image(\n",
        "                            lr_thermal_file, hr_optical_file, hr_thermal_gt_file,\n",
        "                            st.session_state.model, colormap\n",
        "                        )\n",
        "\n",
        "                        (lr_thermal_pil, hr_optical_pil, output_gray_np, output_colored,\n",
        "                         metrics, heatmap, difference_map, hotspot_viz, hotspot_info, surface_3d) = results\n",
        "\n",
        "                        st.session_state.results = {\n",
        "                            'lr_thermal': lr_thermal_pil,\n",
        "                            'hr_optical': hr_optical_pil,\n",
        "                            'output_gray_np': output_gray_np,\n",
        "                            'output_colored': output_colored,\n",
        "                            'hr_thermal_gt': Image.open(hr_thermal_gt_file).convert(\"L\") if hr_thermal_gt_file else None,\n",
        "                            'metrics': metrics,\n",
        "                            'heatmap': heatmap,\n",
        "                            'difference_map': difference_map,\n",
        "                            'hotspot_viz': hotspot_viz,\n",
        "                            'hotspot_info': hotspot_info,\n",
        "                            'surface_3d': surface_3d\n",
        "                        }\n",
        "                        st.success(\"✅ Processing complete!\")\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"❌ Error during processing: {str(e)}\")\n",
        "                        import traceback\n",
        "                        st.error(traceback.format_exc())\n",
        "\n",
        "        # Display results\n",
        "        if 'results' in st.session_state:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## Processing Results\")\n",
        "\n",
        "            # Comparison view\n",
        "            st.markdown(\"### Input-Output Comparison\")\n",
        "            cols_display = st.columns(3 + (1 if st.session_state.results['hr_thermal_gt'] else 0))\n",
        "\n",
        "            with cols_display[0]:\n",
        "                st.markdown(\"#### Input: LR Thermal\")\n",
        "                st.image(st.session_state.results['lr_thermal'], use_container_width=True)\n",
        "\n",
        "            with cols_display[1]:\n",
        "                st.markdown(\"#### Input: HR Optical\")\n",
        "                st.image(st.session_state.results['hr_optical'], use_container_width=True)\n",
        "\n",
        "            if st.session_state.results['hr_thermal_gt']:\n",
        "                with cols_display[2]:\n",
        "                    st.markdown(\"#### Ground Truth\")\n",
        "                    st.image(st.session_state.results['hr_thermal_gt'], use_container_width=True)\n",
        "                with cols_display[3]:\n",
        "                    st.markdown(\"#### AI Output\")\n",
        "                    st.image(st.session_state.results['output_colored'], use_container_width=True)\n",
        "            else:\n",
        "                with cols_display[2]:\n",
        "                    st.markdown(\"#### AI Output\")\n",
        "                    st.image(st.session_state.results['output_colored'], use_container_width=True)\n",
        "\n",
        "            # Enhanced visualizations\n",
        "            st.markdown(\"### Enhanced Visualizations\")\n",
        "            viz_col1, viz_col2 = st.columns(2)\n",
        "\n",
        "            with viz_col1:\n",
        "                st.markdown(\"#### Thermal Output\")\n",
        "                st.image(st.session_state.results['output_colored'],\n",
        "                        caption=\"AI-Generated High-Resolution Thermal Image\",\n",
        "                        use_container_width=True)\n",
        "\n",
        "            with viz_col2:\n",
        "                st.markdown(\"#### Temperature Heatmap\")\n",
        "                st.image(st.session_state.results['heatmap'],\n",
        "                        caption=\"Temperature Distribution with Scale\",\n",
        "                        use_container_width=True)\n",
        "\n",
        "            # NEW: Hotspot Detection\n",
        "            st.markdown(\"### Hotspot Detection & Analysis\")\n",
        "            col_hot1, col_hot2 = st.columns(2)\n",
        "\n",
        "            with col_hot1:\n",
        "                st.image(st.session_state.results['hotspot_viz'],\n",
        "                        caption=\"Detected Hotspots\",\n",
        "                        use_container_width=True)\n",
        "\n",
        "            with col_hot2:\n",
        "                st.markdown(\"#### Hotspot Summary\")\n",
        "                if st.session_state.results['hotspot_info']:\n",
        "                    for idx, spot in enumerate(st.session_state.results['hotspot_info'][:5], 1):\n",
        "                        st.markdown(\"\"\"\n",
        "                        **Hotspot {idx}:**\n",
        "                        - Max Temp: {spot['max_temp']:.2f}°C\n",
        "                        - Area: {spot['area']} pixels\n",
        "                        - Center: ({spot['center'][1]:.0f}, {spot['center'][0]:.0f})\n",
        "                        \"\"\")\n",
        "                    st.info(f\"Total hotspots detected: {len(st.session_state.results['hotspot_info'])}\")\n",
        "                else:\n",
        "                    st.info(\"No significant hotspots detected\")\n",
        "\n",
        "            # NEW: 3D Visualization\n",
        "            st.markdown(\"### 3D Temperature Surface\")\n",
        "            st.image(st.session_state.results['surface_3d'],\n",
        "                    caption=\"3D Temperature Surface Visualization\",\n",
        "                    use_container_width=True)\n",
        "\n",
        "            # Display difference map if available\n",
        "            if st.session_state.results['difference_map']:\n",
        "                st.markdown(\"### Error Analysis\")\n",
        "                st.image(st.session_state.results['difference_map'],\n",
        "                        caption=\"Prediction Error Map (darker = lower error)\",\n",
        "                        use_container_width=True)\n",
        "\n",
        "            # Display Metrics\n",
        "            if st.session_state.results['metrics']:\n",
        "                st.markdown(\"### Evaluation Metrics\")\n",
        "                metrics = st.session_state.results['metrics']\n",
        "\n",
        "                st.markdown('<div class=\"metric-container\">', unsafe_allow_html=True)\n",
        "                if 'psnr' in metrics:\n",
        "                    st.markdown(f'<div class=\"metric-item\"><strong>{metrics[\"psnr\"]:.2f}</strong>PSNR (dB)</div>', unsafe_allow_html=True)\n",
        "                if 'ssim' in metrics:\n",
        "                    st.markdown(f'<div class=\"metric-item\"><strong>{metrics[\"ssim\"]:.4f}</strong>SSIM</div>', unsafe_allow_html=True)\n",
        "                if 'diss' in metrics:\n",
        "                    st.markdown(f'<div class=\"metric-item\"><strong>{metrics[\"diss\"]:.4f}</strong>DISS</div>', unsafe_allow_html=True)\n",
        "                if 'rmse' in metrics:\n",
        "                    st.markdown(f'<div class=\"metric-item\"><strong>{metrics[\"rmse\"]:.2f}</strong>RMSE (K)</div>', unsafe_allow_html=True)\n",
        "                if 'lpips' in metrics and not np.isnan(metrics['lpips']):\n",
        "                    st.markdown(f'<div class=\"metric-item\"><strong>{metrics[\"lpips\"]:.4f}</strong>LPIPS</div>', unsafe_allow_html=True)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "                # Metric explanations\n",
        "                with st.expander(\"Understanding the Metrics\"):\n",
        "                    st.markdown(\"\"\"\n",
        "                    - **PSNR (Peak Signal-to-Noise Ratio)**: Higher is better. >30dB is excellent.\n",
        "                    - **SSIM (Structural Similarity Index)**: Ranges 0-1. Closer to 1 means better structural similarity.\n",
        "                    - **DISS (Dissimilarity)**: Inverse of SSIM. Lower is better.\n",
        "                    - **RMSE (Root Mean Square Error)**: Temperature accuracy in Kelvin. Lower is better.\n",
        "                    - **LPIPS (Learned Perceptual Image Patch Similarity)**: Lower means better perceptual quality.\n",
        "                    \"\"\")\n",
        "\n",
        "            # Temperature statistics\n",
        "            st.markdown(\"### Temperature Statistics\")\n",
        "            temp_kelvin = st.session_state.results['output_gray_np'] * 100 + 263.15\n",
        "            temp_celsius = temp_kelvin - 273.15\n",
        "            temp_fahrenheit = temp_celsius * 9/5 + 32\n",
        "\n",
        "            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)\n",
        "\n",
        "            with col_stat1:\n",
        "                st.metric(\"Min Temperature\",\n",
        "                         f\"{temp_celsius.min():.2f}°C\",\n",
        "                         f\"{temp_fahrenheit.min():.2f}°F\")\n",
        "            with col_stat2:\n",
        "                st.metric(\"Max Temperature\",\n",
        "                         f\"{temp_celsius.max():.2f}°C\",\n",
        "                         f\"{temp_fahrenheit.max():.2f}°F\")\n",
        "            with col_stat3:\n",
        "                st.metric(\"Mean Temperature\",\n",
        "                         f\"{temp_celsius.mean():.2f}°C\",\n",
        "                         f\"{temp_fahrenheit.mean():.2f}°F\")\n",
        "            with col_stat4:\n",
        "                st.metric(\"Std Deviation\",\n",
        "                         f\"{temp_celsius.std():.2f}°C\",\n",
        "                         f\"{temp_fahrenheit.std():.2f}°F\")\n",
        "\n",
        "            # Temperature distribution histogram\n",
        "            st.markdown(\"### Temperature Distribution\")\n",
        "            fig_hist, ax_hist = plt.subplots(figsize=(10, 4))\n",
        "            ax_hist.hist(temp_celsius.flatten(), bins=50, color='#667eea', alpha=0.7, edgecolor='black')\n",
        "            ax_hist.set_xlabel('Temperature (°C)', fontsize=12)\n",
        "            ax_hist.set_ylabel('Frequency', fontsize=12)\n",
        "            ax_hist.set_title('Temperature Distribution Histogram', fontsize=14, fontweight='bold')\n",
        "            ax_hist.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig_hist)\n",
        "            plt.close()\n",
        "\n",
        "            # Download options\n",
        "            st.markdown(\"### Download Options\")\n",
        "\n",
        "            # Generate CSV data\n",
        "            temp_kelvin = st.session_state.results['output_gray_np'] * 100 + 263.15\n",
        "            temp_celsius = temp_kelvin - 273.15\n",
        "            temp_csv = export_temperature_data(temp_celsius)\n",
        "\n",
        "            col_dl1, col_dl2, col_dl3, col_dl4, col_dl5, col_dl6 = st.columns(6)\n",
        "\n",
        "            with col_dl1:\n",
        "                st.download_button(\n",
        "                    label=\"LR Thermal\",\n",
        "                    data=pil_to_bytes(st.session_state.results['lr_thermal']),\n",
        "                    file_name=f\"lr_thermal_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "            with col_dl2:\n",
        "                st.download_button(\n",
        "                    label=\"HR Optical\",\n",
        "                    data=pil_to_bytes(st.session_state.results['hr_optical']),\n",
        "                    file_name=f\"hr_optical_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "            with col_dl3:\n",
        "                st.download_button(\n",
        "                    label=\"HR Thermal\",\n",
        "                    data=pil_to_bytes(st.session_state.results['output_colored']),\n",
        "                    file_name=f\"hr_thermal_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "            with col_dl4:\n",
        "                st.download_button(\n",
        "                    label=\"Heatmap\",\n",
        "                    data=pil_to_bytes(st.session_state.results['heatmap']),\n",
        "                    file_name=f\"heatmap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\",\n",
        "                    mime=\"image/png\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "            with col_dl5:\n",
        "                st.download_button(\n",
        "                    label=\"CSV Data\",\n",
        "                    data=temp_csv,\n",
        "                    file_name=f\"temperature_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                    use_container_width=True\n",
        "                )\n",
        "\n",
        "            with col_dl6:\n",
        "                zip_data = create_download_zip(\n",
        "                    st.session_state.results['lr_thermal'],\n",
        "                    st.session_state.results['hr_optical'],\n",
        "                    st.session_state.results['output_colored'],\n",
        "                    st.session_state.results['heatmap'],\n",
        "                    st.session_state.results['hr_thermal_gt'],\n",
        "                    st.session_state.results['difference_map'],\n",
        "                    st.session_state.results['hotspot_viz'],\n",
        "                    st.session_state.results['surface_3d'],\n",
        "                    temp_csv\n",
        "                )\n",
        "                st.download_button(\n",
        "                    label=\"All Files\",\n",
        "                    data=zip_data,\n",
        "                    file_name=f\"vayu_drishya_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\",\n",
        "                    mime=\"application/zip\"\n",
        "                                    )\n",
        "\n",
        "    with tab3:\n",
        "        st.markdown(\"### Advanced Analysis Tools\")\n",
        "\n",
        "        if 'results' not in st.session_state:\n",
        "            st.info(\"Please process an image in the 'Image Processing' tab first to use advanced analysis tools\")\n",
        "        else:\n",
        "            temp_celsius = (st.session_state.results['output_gray_np'] * 100 + 263.15) - 273.15\n",
        "\n",
        "            # Temperature Profile Analysis\n",
        "            st.markdown(\"#### Temperature Profile Analysis\")\n",
        "            st.markdown(\"Analyze temperature distribution along a line\")\n",
        "\n",
        "            col_prof1, col_prof2 = st.columns(2)\n",
        "            with col_prof1:\n",
        "                profile_axis = st.radio(\"Select axis:\", [\"Horizontal\", \"Vertical\"], horizontal=True)\n",
        "            with col_prof2:\n",
        "                profile_position = st.slider(\"Position (0=top/left, 1=bottom/right):\",\n",
        "                                            0.0, 1.0, 0.5, 0.01)\n",
        "\n",
        "            if st.button(\"Generate Temperature Profile\"):\n",
        "                with st.spinner(\"Creating temperature profile...\"):\n",
        "                    profile_img = create_thermal_profile(\n",
        "                        temp_celsius,\n",
        "                        axis=profile_axis.lower(),\n",
        "                        position=profile_position\n",
        "                    )\n",
        "                    st.image(profile_img, use_container_width=True)\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # ROI Analysis\n",
        "            st.markdown(\"#### Region of Interest (ROI) Analysis\")\n",
        "            st.markdown(\"Analyze a specific region of the thermal image\")\n",
        "\n",
        "            col_roi1, col_roi2 = st.columns(2)\n",
        "            with col_roi1:\n",
        "                roi_x1 = st.number_input(\"X1 (left)\", 0, temp_celsius.shape[1]-1, 0)\n",
        "                roi_y1 = st.number_input(\"Y1 (top)\", 0, temp_celsius.shape[0]-1, 0)\n",
        "            with col_roi2:\n",
        "                roi_x2 = st.number_input(\"X2 (right)\", 0, temp_celsius.shape[1]-1, temp_celsius.shape[1]//2)\n",
        "                roi_y2 = st.number_input(\"Y2 (bottom)\", 0, temp_celsius.shape[0]-1, temp_celsius.shape[0]//2)\n",
        "\n",
        "            if st.button(\"Analyze ROI\"):\n",
        "                if roi_x2 > roi_x1 and roi_y2 > roi_y1:\n",
        "                    stats, roi = create_roi_analysis(temp_celsius, (roi_x1, roi_y1, roi_x2, roi_y2))\n",
        "\n",
        "                    # Show ROI on image\n",
        "                    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "                    im = ax.imshow(temp_celsius, cmap='inferno')\n",
        "                    rect = plt.Rectangle((roi_x1, roi_y1), roi_x2-roi_x1, roi_y2-roi_y1,\n",
        "                                        fill=False, edgecolor='cyan', linewidth=3)\n",
        "                    ax.add_patch(rect)\n",
        "                    plt.colorbar(im, ax=ax, label='Temperature (°C)')\n",
        "                    ax.set_title('Region of Interest', fontsize=14, fontweight='bold')\n",
        "                    ax.axis('off')\n",
        "                    st.pyplot(fig)\n",
        "                    plt.close()\n",
        "\n",
        "                    # Display statistics\n",
        "                    st.markdown(\"#### ROI Statistics\")\n",
        "                    col_s1, col_s2, col_s3, col_s4, col_s5 = st.columns(5)\n",
        "                    col_s1.metric(\"Min\", f\"{stats['min']:.2f}°C\")\n",
        "                    col_s2.metric(\"Max\", f\"{stats['max']:.2f}°C\")\n",
        "                    col_s3.metric(\"Mean\", f\"{stats['mean']:.2f}°C\")\n",
        "                    col_s4.metric(\"Median\", f\"{stats['median']:.2f}°C\")\n",
        "                    col_s5.metric(\"Std Dev\", f\"{stats['std']:.2f}°C\")\n",
        "                else:\n",
        "                    st.error(\"Invalid ROI coordinates. X2 must be > X1 and Y2 must be > Y1\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Comparison Tools\n",
        "            st.markdown(\"#### Image Comparison\")\n",
        "\n",
        "            if st.session_state.results.get('hr_thermal_gt'):\n",
        "                comparison_type = st.selectbox(\n",
        "                    \"Select comparison:\",\n",
        "                    [\"Input LR vs Output HR\", \"Ground Truth vs Prediction\", \"Before vs After\"]\n",
        "                )\n",
        "\n",
        "                if st.button(\"Generate Comparison\"):\n",
        "                    if comparison_type == \"Input LR vs Output HR\":\n",
        "                        comp_img = compare_side_by_side(\n",
        "                            st.session_state.results['lr_thermal'],\n",
        "                            st.session_state.results['output_colored'],\n",
        "                            \"Low Resolution Input\",\n",
        "                            \"High Resolution Output\"\n",
        "                        )\n",
        "                    elif comparison_type == \"Ground Truth vs Prediction\":\n",
        "                        comp_img = compare_side_by_side(\n",
        "                            st.session_state.results['hr_thermal_gt'],\n",
        "                            st.session_state.results['output_colored'],\n",
        "                            \"Ground Truth\",\n",
        "                            \"AI Prediction\"\n",
        "                        )\n",
        "                    else:\n",
        "                        comp_img = compare_side_by_side(\n",
        "                            st.session_state.results['lr_thermal'],\n",
        "                            st.session_state.results['output_colored'],\n",
        "                            \"Before Enhancement\",\n",
        "                            \"After Enhancement\"\n",
        "                        )\n",
        "                    st.image(comp_img, use_container_width=True)\n",
        "            else:\n",
        "                st.info(\"Upload ground truth in the Image Processing tab for more comparison options\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            # Custom Hotspot Threshold\n",
        "            st.markdown(\"#### Custom Hotspot Detection\")\n",
        "            hotspot_threshold = st.slider(\n",
        "                \"Hotspot threshold (percentile):\",\n",
        "                50, 99, 90, 1,\n",
        "                help=\"Higher values detect only the hottest areas\"\n",
        "            )\n",
        "\n",
        "            if st.button(\"Detect Hotspots with Custom Threshold\"):\n",
        "                with st.spinner(\"Detecting hotspots...\"):\n",
        "                    hotspots, hotspot_info = detect_hotspots(temp_celsius, hotspot_threshold)\n",
        "                    custom_hotspot_viz = create_hotspot_visualization(temp_celsius, hotspots, hotspot_info)\n",
        "\n",
        "                    col_hs1, col_hs2 = st.columns(2)\n",
        "                    with col_hs1:\n",
        "                        st.image(custom_hotspot_viz, use_container_width=True)\n",
        "                    with col_hs2:\n",
        "                        st.markdown(f\"#### Found {len(hotspot_info)} hotspots\")\n",
        "                        for idx, spot in enumerate(hotspot_info[:10], 1):\n",
        "                            st.markdown(f\"**{idx}.** {spot['max_temp']:.2f}°C | Area: {spot['area']}px\")\n",
        "\n",
        "    with tab2:\n",
        "        st.markdown(\"### Batch Processing\")\n",
        "        st.info(\"Batch processing feature - Upload multiple image pairs for processing\")\n",
        "\n",
        "        st.markdown(\"#### Upload Multiple Image Pairs\")\n",
        "        col_batch1, col_batch2 = st.columns(2)\n",
        "\n",
        "        with col_batch1:\n",
        "            batch_lr_files = st.file_uploader(\n",
        "                \"Upload multiple LR thermal images\",\n",
        "                type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "                accept_multiple_files=True,\n",
        "                key=\"batch_lr\"\n",
        "            )\n",
        "\n",
        "        with col_batch2:\n",
        "            batch_hr_files = st.file_uploader(\n",
        "                \"Upload multiple HR optical images\",\n",
        "                type=[\"png\", \"jpg\", \"jpeg\"],\n",
        "                accept_multiple_files=True,\n",
        "                key=\"batch_hr\"\n",
        "            )\n",
        "\n",
        "        if batch_lr_files and batch_hr_files:\n",
        "            if len(batch_lr_files) != len(batch_hr_files):\n",
        "                st.warning(\"Number of LR and HR images must match!\")\n",
        "            else:\n",
        "                st.success(f\"✅ {len(batch_lr_files)} image pairs ready for processing\")\n",
        "\n",
        "                if st.button(\"Process All Images\", key=\"batch_process\"):\n",
        "                    progress_bar = st.progress(0)\n",
        "                    status_text = st.empty()\n",
        "\n",
        "                    batch_results = []\n",
        "                    for idx, (lr_file, hr_file) in enumerate(zip(batch_lr_files, batch_hr_files)):\n",
        "                        status_text.text(f\"Processing image {idx+1}/{len(batch_lr_files)}...\")\n",
        "\n",
        "                        try:\n",
        "                            results = process_image(lr_file, hr_file, None,\n",
        "                                                   st.session_state.model, colormap)\n",
        "                            batch_results.append({\n",
        "                                'lr_name': lr_file.name,\n",
        "                                'hr_name': hr_file.name,\n",
        "                                'output': results[3],\n",
        "                                'heatmap': results[5]\n",
        "                            })\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error processing {lr_file.name}: {e}\")\n",
        "\n",
        "                        progress_bar.progress((idx + 1) / len(batch_lr_files))\n",
        "\n",
        "                    status_text.text(\"✅ Batch processing complete!\")\n",
        "                    st.session_state.batch_results = batch_results\n",
        "\n",
        "                    # Create batch download\n",
        "                    zip_buffer = io.BytesIO()\n",
        "                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
        "                        for idx, result in enumerate(batch_results):\n",
        "                            zip_file.writestr(f'batch_{idx+1}_output.png',\n",
        "                                            pil_to_bytes(result['output']))\n",
        "                            zip_file.writestr(f'batch_{idx+1}_heatmap.png',\n",
        "                                            pil_to_bytes(result['heatmap']))\n",
        "\n",
        "                    st.download_button(\n",
        "                        label=\"Download All Batch Results\",\n",
        "                        data=zip_buffer.getvalue(),\n",
        "                        file_name=f\"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\",\n",
        "                        mime=\"application/zip\"\n",
        "                    )\n",
        "\n",
        "    with tab4:\n",
        "        st.markdown(\"### Documentation & User Guide\")\n",
        "\n",
        "        st.markdown(\"\"\"\n",
        "        ## How to Use InfraNova\n",
        "\n",
        "        ### Step 1: Prepare Your Images\n",
        "        - **LR Thermal Image**: Low-resolution thermal infrared image (grayscale)\n",
        "        - **HR Optical Image**: High-resolution RGB optical image of the same scene\n",
        "        - **Ground Truth** (optional): High-resolution thermal image for accuracy evaluation\n",
        "\n",
        "        ### Step 2: Upload & Configure\n",
        "        1. Navigate to the \"Image Processing\" tab\n",
        "        2. Upload your LR thermal and HR optical images\n",
        "        3. (Optional) Upload ground truth for metric calculation\n",
        "        4. Select your preferred colormap from the sidebar\n",
        "\n",
        "        ### Step 3: Generate Results\n",
        "        Click the \"Generate Super-Resolution Image\" button to process your images\n",
        "\n",
        "        ### Step 4: Analyze Results\n",
        "        - View input-output comparison\n",
        "        - Examine temperature distribution heatmap\n",
        "        - Review evaluation metrics (if ground truth provided)\n",
        "        - Check temperature statistics\n",
        "\n",
        "        ### Step 5: Download\n",
        "        Download individual images or all results as a ZIP file\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Understanding the Metrics\n",
        "\n",
        "        ### PSNR (Peak Signal-to-Noise Ratio)\n",
        "        - Measures pixel-level accuracy\n",
        "        - **Range**: 20-50 dB (higher is better)\n",
        "        - **Excellent**: > 35 dB\n",
        "        - **Good**: 30-35 dB\n",
        "        - **Acceptable**: 25-30 dB\n",
        "\n",
        "        ### SSIM (Structural Similarity Index)\n",
        "        - Measures perceived quality and structural similarity\n",
        "        - **Range**: 0-1 (closer to 1 is better)\n",
        "        - **Excellent**: > 0.95\n",
        "        - **Good**: 0.90-0.95\n",
        "        - **Acceptable**: 0.85-0.90\n",
        "\n",
        "        ### RMSE (Root Mean Square Error)\n",
        "        - Measures temperature accuracy in Kelvin. Lower is better.\n",
        "        - Indicates average temperature prediction error\n",
        "\n",
        "        ### LPIPS (Learned Perceptual Image Patch Similarity)\n",
        "        - Deep learning-based perceptual metric\n",
        "        - **Range**: 0-1 (lower is better)\n",
        "        - Correlates well with human perception\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Colormap Guide\n",
        "\n",
        "        - **Inferno**: High contrast, excellent for highlighting hot spots\n",
        "        - **Plasma**: Similar to inferno with purple tones\n",
        "        - **Viridis**: Perceptually uniform, colorblind-friendly\n",
        "        - **Hot**: Traditional thermal imaging colors\n",
        "        - **Coolwarm**: Blue (cold) to red (hot) diverging scale\n",
        "        - **Jet**: Classic rainbow colormap (not perceptually uniform)\n",
        "        - **Turbo**: Improved version of jet\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Technical Details\n",
        "\n",
        "        ### Model Architecture\n",
        "        - **Type**: Enhanced U-Net with Attention Mechanisms\n",
        "        - **Training**: GAN-based adversarial training\n",
        "        - **Input**: 4 channels (1 thermal + 3 RGB)\n",
        "        - **Output**: 1 channel (enhanced thermal)\n",
        "        - **Parameters**: ~31 million\n",
        "\n",
        "        ### Processing Pipeline\n",
        "        1. Input preprocessing and normalization\n",
        "        2. Bicubic upsampling of LR thermal\n",
        "        3. Multi-modal feature fusion\n",
        "        4. U-Net encoding with attention\n",
        "        5. Bottleneck processing\n",
        "        6. U-Net decoding with skip connections\n",
        "        7. Output denormalization and colormap application\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Applications\n",
        "\n",
        "        ### Urban Planning\n",
        "        - Heat island effect mapping\n",
        "        - Energy efficiency assessment\n",
        "        - Building thermal analysis\n",
        "\n",
        "        ### Agriculture\n",
        "        - Crop health monitoring\n",
        "        - Irrigation management\n",
        "        - Yield prediction\n",
        "\n",
        "        ### Disaster Management\n",
        "        - Wildfire detection and tracking\n",
        "        - Search and rescue operations\n",
        "        - Damage assessment\n",
        "\n",
        "        ### Infrastructure\n",
        "        - Bridge and road inspection\n",
        "        - Power line monitoring\n",
        "        - Pipeline leak detection\n",
        "\n",
        "        ### Environmental Science\n",
        "        - Climate change research\n",
        "        - Ecosystem monitoring\n",
        "        - Water temperature mapping\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## System Requirements\n",
        "\n",
        "        ### Recommended\n",
        "        - GPU: NVIDIA GPU with CUDA support\n",
        "        - RAM: 8GB+\n",
        "        - Storage: 2GB+ free space\n",
        "\n",
        "        ### Minimum\n",
        "        - CPU: Multi-core processor\n",
        "        - RAM: 4GB+\n",
        "        - Storage: 1GB+ free space\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Troubleshooting\n",
        "\n",
        "        ### Model Not Loading\n",
        "        - Ensure model file exists at specified path\n",
        "        - Check Google Drive is mounted correctly\n",
        "        - Verify model file is not corrupted\n",
        "\n",
        "        ### Out of Memory Error\n",
        "        - Reduce image resolution\n",
        "        - Process images individually instead of batch\n",
        "        - Restart runtime and clear cache\n",
        "\n",
        "        ### Poor Results\n",
        "        - Ensure images are from the same scene\n",
        "        - Check image alignment\n",
        "        - Verify thermal image quality\n",
        "        - Try different colormap for better visualization\n",
        "\n",
        "        ---\n",
        "\n",
        "        ## Citation\n",
        "\n",
        "        If you use InfraNova in your research, please cite:\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "\n",
        "    # Footer\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"\"\"\n",
        "    <div style='text-align: center; color: #888;'>\n",
        "        <p>Powered by Enhanced U-Net + GAN Architecture</p>\n",
        "        <p>Developed by:PARASAD HIRAGOND</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "969f9877",
        "outputId": "4dd3ad6c-e5c8-447d-90cb-b24322e7c23f"
      },
      "source": [
        "import os\n",
        "\n",
        "path_to_check = \"/content/drive/MyDrive/BD\"\n",
        "\n",
        "if os.path.exists(path_to_check):\n",
        "    print(f\"✓ Path exists: {path_to_check}\")\n",
        "    if os.path.isdir(path_to_check):\n",
        "        print(f\"✓ Path is a directory: {path_to_check}\")\n",
        "        try:\n",
        "            contents = os.listdir(path_to_check)\n",
        "            if contents:\n",
        "                print(f\"✓ Directory is not empty. First 5 items: {contents[:5]}\")\n",
        "                print(f\"Total items: {len(contents)}\")\n",
        "            else:\n",
        "                print(f\"⚠️ Directory exists but is empty: {path_to_check}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error listing directory contents for {path_to_check}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Path exists but is not a directory: {path_to_check}\")\n",
        "        print(\"Please ensure this path points to a folder containing your thermal images.\")\n",
        "else:\n",
        "    print(f\"❌ Path does not exist: {path_to_check}\")\n",
        "    print(\"Please verify that 'BD' is correctly placed in your Google Drive's MyDrive folder and accessible.\")\n",
        "\n",
        "\n",
        "path_to_check = \"/content/drive/MyDrive/HR RGB\"\n",
        "if os.path.exists(path_to_check):\n",
        "    print(f\"✓ Path exists: {path_to_check}\")\n",
        "else:\n",
        "    print(f\"❌ Path does not exist: {path_to_check}\")\n",
        "\n",
        "path_to_check = \"/content/drive/MyDrive/GT thermal\"\n",
        "if os.path.exists(path_to_check):\n",
        "    print(f\"✓ Path exists: {path_to_check}\")\n",
        "else:\n",
        "    print(f\"❌ Path does not exist: {path_to_check}\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Path exists: /content/drive/MyDrive/BD\n",
            "✓ Path is a directory: /content/drive/MyDrive/BD\n",
            "✓ Directory is not empty. First 5 items: ['00095ix4.png', '00075ix4.png', '00072ix4.png', '00077ix4.png', '00080ix4.png']\n",
            "Total items: 1025\n",
            "✓ Path exists: /content/drive/MyDrive/HR RGB\n",
            "✓ Path exists: /content/drive/MyDrive/GT thermal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test - no public URL\n",
        "!streamlit run /content/app.py\n",
        "\n",
        "# Then use Colab's port forwarding (it will show a link in output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CIfHgbDSZlc",
        "outputId": "e2c738a5-55d4-43ca-c18d-33636816e775",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.30.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.163.12:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72655807"
      },
      "source": [
        "### Install Libraries for New Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b02d4bc",
        "outputId": "7fa53576-0646-4b91-d81c-db31e62939f3"
      },
      "source": [
        "!pip install lpips -q\n",
        "# scikit-image already installed, which should cover DISS and FSIM"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dfe32c5"
      },
      "source": [
        "!pip install pyngrok -q"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# --- PASTE YOUR NGROK AUTHTOKEN HERE ---\n",
        "AUTHTOKEN = \"357B79LZjKUC9kY5aChCXt8ujSt_6CRSX1R1L4JVwGPSipsAK\"\n",
        "\n",
        "# Run streamlit\n",
        "# Removed background execution and output redirection to see potential errors\n",
        "print(\"Starting Streamlit app...\")\n",
        "!streamlit run app.py --server.port 8501\n",
        "\n",
        "\n",
        "# Set up the ngrok tunnel\n",
        "# This part might not be reached if streamlit fails to start\n",
        "# ngrok.set_auth_token(AUTHTOKEN)\n",
        "# public_url = ngrok.connect(8501)\n",
        "\n",
        "# Print the public URL\n",
        "# print(f\"Your Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "id": "PctZTdHoK9Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ae0d37-c01d-498b-b058-1713296a4bd5",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Streamlit app...\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.30.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.163.12:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53489b07",
        "outputId": "f5598047-dcfe-434b-af1b-3d95c0cac202",
        "collapsed": true
      },
      "source": [
        "import os\n",
        "import signal\n",
        "import time\n",
        "\n",
        "print(\"Attempting to find and stop the Streamlit process on port 8501...\")\n",
        "\n",
        "try:\n",
        "    # Find the process ID (PID) listening on port 8501\n",
        "    # lsof -i :8501 -t gets the PID(s) of processes using port 8501\n",
        "    # -t option returns only the PID\n",
        "    pid_command = \"lsof -i :8501 -t\"\n",
        "    pid_output = os.popen(pid_command).read().strip()\n",
        "\n",
        "    if pid_output:\n",
        "        pids = pid_output.split('\\n')\n",
        "        print(f\"Found process(es) on port 8501 with PID(s): {', '.join(pids)}\")\n",
        "\n",
        "        for pid in pids:\n",
        "            try:\n",
        "                pid_int = int(pid)\n",
        "                 # Check if the process is still running before attempting to kill\n",
        "                os.kill(pid_int, 0) # Signal 0 checks if the process exists\n",
        "\n",
        "                print(f\"Attempting to send SIGTERM to PID {pid}\")\n",
        "                os.kill(pid_int, signal.SIGTERM) # Use SIGTERM first\n",
        "                time.sleep(2) # Give it a moment\n",
        "\n",
        "                # Check if it stopped\n",
        "                try:\n",
        "                    os.kill(pid_int, 0)\n",
        "                    print(f\"PID {pid} still running after SIGTERM. Attempting SIGKILL...\")\n",
        "                    os.kill(pid_int, signal.SIGKILL) # Use SIGKILL if SIGTERM didn't work\n",
        "                    print(f\"Sent SIGKILL to PID {pid}\")\n",
        "                    time.sleep(2) # Give it another moment\n",
        "                except ProcessLookupError:\n",
        "                    print(f\"PID {pid} stopped after SIGTERM.\")\n",
        "\n",
        "\n",
        "            except ProcessLookupError:\n",
        "                print(f\"Process with PID {pid} not found. It might have already stopped.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error managing process {pid}: {e}\")\n",
        "\n",
        "        # Final verification\n",
        "        pid_output_after = os.popen(pid_command).read().strip()\n",
        "        if not pid_output_after:\n",
        "            print(\"✓ Process on port 8501 successfully stopped.\")\n",
        "        else:\n",
        "            print(\"⚠️ Process on port 8501 may still be running.\")\n",
        "            print(\"Manual intervention might be required (e.g., using `kill -9 <PID>` in a terminal).\")\n",
        "\n",
        "    else:\n",
        "        print(\"No process found running on port 8501.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to find or stop the process: {e}\")\n",
        "\n",
        "print(\"\\nNow you can try running the Streamlit app with ngrok again.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to find and stop the Streamlit process on port 8501...\n",
            "No process found running on port 8501.\n",
            "\n",
            "Now you can try running the Streamlit app with ngrok again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1f36c3f",
        "outputId": "8394003d-383a-4d99-9896-73450864cec1",
        "collapsed": true
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "import signal\n",
        "\n",
        "print(\"Attempting to find and stop any running ngrok processes...\")\n",
        "\n",
        "try:\n",
        "    # Find the PID of the ngrok process\n",
        "    # You might need to adjust this command based on how ngrok is running\n",
        "    # This command assumes ngrok is run directly and looks for the process name 'ngrok'\n",
        "    pid_command = \"pgrep ngrok\"\n",
        "    pid_output = os.popen(pid_command).read().strip()\n",
        "\n",
        "    if pid_output:\n",
        "        pids = pid_output.split('\\n')\n",
        "        print(f\"Found ngrok process(es) with PID(s): {', '.join(pids)}\")\n",
        "\n",
        "        for pid in pids:\n",
        "            try:\n",
        "                pid_int = int(pid)\n",
        "                # Check if the process is still running before attempting to kill\n",
        "                os.kill(pid_int, 0) # Signal 0 checks if the process exists\n",
        "\n",
        "                print(f\"Attempting to send SIGTERM to PID {pid}\")\n",
        "                os.kill(pid_int, signal.SIGTERM) # Use SIGTERM first\n",
        "                time.sleep(2) # Give it a moment\n",
        "\n",
        "                # Check if it stopped\n",
        "                try:\n",
        "                    os.kill(pid_int, 0)\n",
        "                    print(f\"PID {pid} still running after SIGTERM. Attempting SIGKILL...\")\n",
        "                    os.kill(pid_int, signal.SIGKILL) # Use SIGKILL if SIGTERM didn't work\n",
        "                    print(f\"Sent SIGKILL to PID {pid}\")\n",
        "                    time.sleep(2) # Give it another moment\n",
        "                except ProcessLookupError:\n",
        "                    print(f\"PID {pid} stopped after SIGTERM.\")\n",
        "\n",
        "            except ProcessLookupError:\n",
        "                print(f\"Process with PID {pid} not found. It might have already stopped.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error managing ngrok process {pid}: {e}\")\n",
        "\n",
        "        # Final verification\n",
        "        pid_output_after = os.popen(pid_command).read().strip()\n",
        "        if not pid_output_after:\n",
        "            print(\"✓ All ngrok processes successfully stopped.\")\n",
        "        else:\n",
        "            print(\"⚠️ Some ngrok processes may still be running.\")\n",
        "            print(\"Manual intervention might be required (e.g., using `kill -9 <PID>` in a terminal).\")\n",
        "\n",
        "    else:\n",
        "        print(\"No ngrok process found running.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while trying to find or stop ngrok processes: {e}\")\n",
        "\n",
        "# Alternative method using pyngrok's built-in kill\n",
        "print(\"\\nAttempting to kill ngrok processes using pyngrok.kill()...\")\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    print(\"✓ pyngrok.kill() executed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"pyngrok.kill() failed or no processes were running: {e}\")\n",
        "\n",
        "print(\"\\nNow you can try running the Streamlit app with ngrok again.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to find and stop any running ngrok processes...\n",
            "No ngrok process found running.\n",
            "\n",
            "Attempting to kill ngrok processes using pyngrok.kill()...\n",
            "✓ pyngrok.kill() executed successfully.\n",
            "\n",
            "Now you can try running the Streamlit app with ngrok again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "490353d9",
        "outputId": "83c75d05-2975-4d5b-c387-68e219ad9309"
      },
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# --- PASTE YOUR NGROK AUTHTOKEN HERE ---\n",
        "# You can get one at https://ngrok.com/\n",
        "AUTHTOKEN = \"34IEGqITKeE41WICwKh35RhsfnC_6nzq1e9KhZTEoY7rd7JpF\" # Replace with your actual auth token\n",
        "\n",
        "# Install streamlit to ensure it's available in this execution context\n",
        "print(\"Ensuring Streamlit is installed...\")\n",
        "!pip install streamlit -q\n",
        "print(\"Streamlit installation check complete.\")\n",
        "\n",
        "# Terminate any previous ngrok tunnels to free up the endpoint\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    print(\"Killed all ngrok processes to ensure a clean start.\")\n",
        "except Exception as e:\n",
        "    print(f\"No ngrok processes running or error killing: {e}\")\n",
        "\n",
        "# Run streamlit in the background\n",
        "print(\"Starting Streamlit app in background...\")\n",
        "!nohup streamlit run app.py --server.port 8501 > streamlit.log 2>&1 &\n",
        "print(\"Streamlit app started.\")\n",
        "\n",
        "\n",
        "# Set up the ngrok tunnel\n",
        "ngrok.set_auth_token(AUTHTOKEN)\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "# Print the public URL\n",
        "print(f\"Your Streamlit app is live at: {public_url}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensuring Streamlit is installed...\n",
            "Streamlit installation check complete.\n",
            "Killed all ngrok processes to ensure a clean start.\n",
            "Starting Streamlit app in background...\n",
            "Streamlit app started.\n",
            "Your Streamlit app is live at: NgrokTunnel: \"https://nonjudiciable-festinately-minh.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MGiaYZxZ9AJB"
      }
    }
  ]
}